{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8201044,"sourceType":"datasetVersion","datasetId":4854718},{"sourceId":8609366,"sourceType":"datasetVersion","datasetId":5151875},{"sourceId":8609519,"sourceType":"datasetVersion","datasetId":5151989},{"sourceId":8609887,"sourceType":"datasetVersion","datasetId":5152259},{"sourceId":8609923,"sourceType":"datasetVersion","datasetId":5152289},{"sourceId":8610250,"sourceType":"datasetVersion","datasetId":5152544}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tayyubahmed/bone-fracture-detection?scriptVersionId=181953547\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#dependencies \nimport numpy as np\nimport pandas as pd \nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Conv2D, Dropout, Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Here we load images, reduce their size, standardize them, convert them into numpy arrays, we have used exception handling to handle corrupt images\n\ndef load_images(directory):\n    images = []\n    for filename in os.listdir(directory):\n        try:\n            img = Image.open(os.path.join(directory, filename))\n            img = img.resize((128, 128))\n            img = img.convert('RGB')\n            img = np.array(img) / 255.0\n            images.append(img)\n        except OSError as e:\n            print(f\"Error loading {os.path.join(directory, filename)}: {e}\")\n            continue\n    return images\n\n#     Loads images from a specified directory.\n#     Resizes each image to 128x128 pixels.\n#     Converts each image to RGB mode.\n#     Normalizes the pixel values of each image to the range [0, 1].\n#     Handles exceptions for corrupt images to ensure the process continues smoothly.\n#     Stores the processed images in a list and returns the list.","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:31:46.985191Z","iopub.execute_input":"2024-06-07T03:31:46.985757Z","iopub.status.idle":"2024-06-07T03:31:46.992576Z","shell.execute_reply.started":"2024-06-07T03:31:46.985726Z","shell.execute_reply":"2024-06-07T03:31:46.991598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Providing storage links to our dataset divided into Training,Testing and Validation.\n\nfr_test = load_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/fractured')\nfr_train = load_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/fractured')\nfr_val = load_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/fractured')\nno_fr_test = load_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/not fractured')\nno_fr_train = load_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/not fractured')\nno_fr_val = load_images('/kaggle/input/fracture-multi-region-x-ray-data/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/val/not fractured')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Concatenating images of each category into one array for easier understanding and use\n\ntrain_images = np.concatenate((fr_train, no_fr_train))\nval_images = np.concatenate((fr_val, no_fr_val))\ntest_images = np.concatenate((fr_test, no_fr_test))","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:11.201052Z","iopub.execute_input":"2024-06-07T03:33:11.201362Z","iopub.status.idle":"2024-06-07T03:33:13.902322Z","shell.execute_reply.started":"2024-06-07T03:33:11.201333Z","shell.execute_reply":"2024-06-07T03:33:13.901491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#just for checking / troubleshooting\n# train_images\ntrain_images.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:13.903497Z","iopub.execute_input":"2024-06-07T03:33:13.903786Z","iopub.status.idle":"2024-06-07T03:33:13.910782Z","shell.execute_reply.started":"2024-06-07T03:33:13.903761Z","shell.execute_reply":"2024-06-07T03:33:13.909776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a numpy array of labels for fractured and non-fractured where each index corresponds to its respective image in the above numpy array containing the actual images\n\ntrain_labels = np.concatenate((np.ones(len(fr_train)), np.zeros(len(no_fr_train))))\nval_labels = np.concatenate((np.ones(len(fr_val)), np.zeros(len(no_fr_val))))\ntest_labels = np.concatenate((np.ones(len(fr_test)), np.zeros(len(no_fr_test))))","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:13.91229Z","iopub.execute_input":"2024-06-07T03:33:13.912703Z","iopub.status.idle":"2024-06-07T03:33:13.919937Z","shell.execute_reply.started":"2024-06-07T03:33:13.912668Z","shell.execute_reply":"2024-06-07T03:33:13.919029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:13.921319Z","iopub.execute_input":"2024-06-07T03:33:13.921633Z","iopub.status.idle":"2024-06-07T03:33:13.930915Z","shell.execute_reply.started":"2024-06-07T03:33:13.921607Z","shell.execute_reply":"2024-06-07T03:33:13.92997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:13.932321Z","iopub.execute_input":"2024-06-07T03:33:13.932882Z","iopub.status.idle":"2024-06-07T03:33:13.940737Z","shell.execute_reply.started":"2024-06-07T03:33:13.932853Z","shell.execute_reply":"2024-06-07T03:33:13.939823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using CNN model we have used 3 convulational layers of 32 Filter maps of 3x3 size\n#Used a max pooling layer of 2x2 to reduce the size of feature maps for faster computation and translation invariance\n\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu', padding='same'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:13.941838Z","iopub.execute_input":"2024-06-07T03:33:13.942159Z","iopub.status.idle":"2024-06-07T03:33:14.777606Z","shell.execute_reply.started":"2024-06-07T03:33:13.942122Z","shell.execute_reply":"2024-06-07T03:33:14.776799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:14.780423Z","iopub.execute_input":"2024-06-07T03:33:14.780697Z","iopub.status.idle":"2024-06-07T03:33:14.79492Z","shell.execute_reply.started":"2024-06-07T03:33:14.780674Z","shell.execute_reply":"2024-06-07T03:33:14.794188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:14.795895Z","iopub.execute_input":"2024-06-07T03:33:14.796237Z","iopub.status.idle":"2024-06-07T03:33:14.818733Z","shell.execute_reply.started":"2024-06-07T03:33:14.7962Z","shell.execute_reply":"2024-06-07T03:33:14.817876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)\nplt.savefig('architecture.png')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:14.819939Z","iopub.execute_input":"2024-06-07T03:33:14.820714Z","iopub.status.idle":"2024-06-07T03:33:15.140851Z","shell.execute_reply.started":"2024-06-07T03:33:14.82068Z","shell.execute_reply":"2024-06-07T03:33:15.139888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:33:15.141995Z","iopub.execute_input":"2024-06-07T03:33:15.142334Z","iopub.status.idle":"2024-06-07T03:34:14.058693Z","shell.execute_reply.started":"2024-06-07T03:33:15.142307Z","shell.execute_reply":"2024-06-07T03:34:14.05785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"model.weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:34:14.05996Z","iopub.execute_input":"2024-06-07T03:34:14.060918Z","iopub.status.idle":"2024-06-07T03:34:14.306805Z","shell.execute_reply.started":"2024-06-07T03:34:14.06089Z","shell.execute_reply":"2024-06-07T03:34:14.305965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_images, test_labels)\nprint(f'Test Accuracy: {test_accuracy}')\nprint(f'Test Loss: {test_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:34:14.307998Z","iopub.execute_input":"2024-06-07T03:34:14.308346Z","iopub.status.idle":"2024-06-07T03:34:15.896229Z","shell.execute_reply.started":"2024-06-07T03:34:14.308319Z","shell.execute_reply":"2024-06-07T03:34:15.895253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('acc.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:34:15.897522Z","iopub.execute_input":"2024-06-07T03:34:15.897845Z","iopub.status.idle":"2024-06-07T03:34:16.210224Z","shell.execute_reply.started":"2024-06-07T03:34:15.897806Z","shell.execute_reply":"2024-06-07T03:34:16.209329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('loss.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:34:16.211569Z","iopub.execute_input":"2024-06-07T03:34:16.21187Z","iopub.status.idle":"2024-06-07T03:34:16.499149Z","shell.execute_reply.started":"2024-06-07T03:34:16.211844Z","shell.execute_reply":"2024-06-07T03:34:16.498224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Get predictions\npredictions = model.predict(test_images)\ny_pred = (predictions > 0.5).astype('int')\n\n# Create confusion matrix\ncm = confusion_matrix(test_labels, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\nplt.xlabel('Predicted Label')\nplt.ylabel('Actual Label')\nplt.title('Confusion Matrix')\nplt.savefig('confusio_matrix.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:34:16.500456Z","iopub.execute_input":"2024-06-07T03:34:16.500812Z","iopub.status.idle":"2024-06-07T03:34:18.423958Z","shell.execute_reply.started":"2024-06-07T03:34:16.500778Z","shell.execute_reply":"2024-06-07T03:34:18.423052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\n\nweights_path = '/kaggle/input/vgg-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nvgg16_base = VGG16(weights=None, include_top=False, input_shape=(128, 128, 3))\nvgg16_base.load_weights(weights_path)\n\nfor layer in vgg16_base.layers:\n    layer.trainable = False\n\n# Construct the model\nmodel = Sequential([\n    vgg16_base,\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Summary of the model\nmodel.summary()\n\nhistory = model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:34:18.425343Z","iopub.execute_input":"2024-06-07T03:34:18.425782Z","iopub.status.idle":"2024-06-07T03:37:07.097849Z","shell.execute_reply.started":"2024-06-07T03:34:18.425746Z","shell.execute_reply":"2024-06-07T03:37:07.096991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:37:07.103192Z","iopub.execute_input":"2024-06-07T03:37:07.103502Z","iopub.status.idle":"2024-06-07T03:37:16.834769Z","shell.execute_reply.started":"2024-06-07T03:37:07.103467Z","shell.execute_reply":"2024-06-07T03:37:16.833794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\n\n# Path to the downloaded ResNet50 weights file\nweight_path = '/kaggle/input/resnetf/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Load the ResNet50 model without the top layers and without specifying the 'weights' argument\nresnet50_base = ResNet50(weights=None, include_top=False, input_shape=(128, 128, 3))\n\n# Load the pre-downloaded weights\nresnet50_base.load_weights(weight_path)\n\n# Freeze the layers of ResNet50 to retain the pre-trained weights\nfor layer in resnet50_base.layers:\n    layer.trainable = False\n\n# Construct the model\nmodel = Sequential([\n    resnet50_base,\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Summary of the model\nmodel.summary()\n\n# Assuming `train_images`, `train_labels`, `val_images`, `val_labels`, `test_images`, and `test_labels` are defined as per your dataset\n# Train the model\nhistory = model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))\n\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(test_images, test_labels)\nprint(f'Test Loss: {test_loss}')\nprint(f'Test Accuracy: {test_accuracy}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T03:37:16.836289Z","iopub.execute_input":"2024-06-07T03:37:16.836566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}